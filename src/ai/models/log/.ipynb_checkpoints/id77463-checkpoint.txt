Architecture and Training configuration:
Batch size: 8
Input size: 125
Number of Layers: 3
Units Layer 1: 60
Units Layer 2: 30
Units Layer 3: 5
Dropout rate fc NN: 0.2
Cycling LR mode: triangular
Cycling LR base LR: 0.001
Cycling LR max LR: 0.05
- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -
Training phase is started
-------- epoch_no. 0 finished with training loss 0.0646147196813122--------
-------- epoch_no. 1 finished with training loss 0.06719655006701745--------
-------- epoch_no. 2 finished with training loss 0.06451253936447106--------
-------- epoch_no. 3 finished with training loss 0.06135131168531977--------
-------- epoch_no. 4 finished with training loss 0.06075552679137766--------
-------- epoch_no. 5 finished with training loss 0.06102929500212979--------
-------- epoch_no. 6 finished with training loss 0.060310679740110576--------
-------- epoch_no. 7 finished with training loss 0.059257919152598044--------
-------- epoch_no. 8 finished with training loss 0.058897964040577594--------
-------- epoch_no. 9 finished with training loss 0.05875155231882986--------
-------- epoch_no. 10 finished with training loss 0.05852654331776725--------
-------- epoch_no. 11 finished with training loss 0.05784867741711423--------
-------- epoch_no. 12 finished with training loss 0.057488227890817395--------
-------- epoch_no. 13 finished with training loss 0.05747834583686379--------
-------- epoch_no. 14 finished with training loss 0.05761769514249459--------
-------- epoch_no. 15 finished with training loss 0.057189733104195985--------
-------- epoch_no. 16 finished with training loss 0.05691413197582714--------
-------- epoch_no. 17 finished with training loss 0.05688596595484936--------
-------- epoch_no. 18 finished with training loss 0.0568499493152024--------
-------- epoch_no. 19 finished with training loss 0.05658452352987257--------
Training phase is finished
